#In this exercise, your goal is to find the optimal momentum such that the optimizer can find the minimum of the following non-convex function in 20 steps. You will experiment with two different momentum values. For this problem, the learning rate is fixed at 0.01.
#You are provided with the optimize_and_plot() function that takes the learning rate for the first argument. This function will run 20 steps of the SGD optimizer and display the results.
#
#Instruction 1/2
#
#Try a first value for the momentum such that the optimizer gets stuck in the first minimum.
#
#Code
#
## Try a first value for momentum
#mom0 = 0.1
#optimize_and_plot(momentum=mom0)
#
# Instruction 2/2
#
# Try a second value for the momentum such that the optimizer finds the global optimum.
#
# Code
#
## Try a second value for momentum
#mom1 = 0.9184
#optimize_and_plot(momentum=mom1)

